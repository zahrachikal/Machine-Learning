{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhkqSRbsySsB"
      },
      "source": [
        "# Alat Pengoptimalan Model Tensorflow (TMO)\n",
        "\n",
        "Di notebook ini, kami akan mendemonstrasikan cara menggunakan TMO untuk mengoptimalkan model penerapan. Kami melatih model pada kumpulan data MNIST dan kemudian mengoptimalkannya menggunakan TMO. Kami kemudian akan membandingkan ukuran dan keakuratan model yang dioptimalkan dengan model aslinya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ux-2WJySsC"
      },
      "source": [
        "## Siapkan TMO\n",
        "\n",
        "Pertama, kita menginstal TMO dan mengimpor paket yang diperlukan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3A-Qt9MeySsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77237d85-c2da-411a-fb4a-925b425105f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/242.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q tensorflow\n",
        "%pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kobgA4ICySsC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow import keras\n",
        "import pathlib\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETZ5lCP1ySsD"
      },
      "source": [
        "## Kuantisasi Pasca Pelatihan\n",
        "\n",
        "Alat kuantisasi pasca pelatihan mengubah bobot model terlatih dari presisi 32 bit menjadi 8 bit. Alat ini mengonversi model TensorFlow float yang sudah dilatih saat kita mengonversinya ke format TensorFlow Lite menggunakan [TensorFlow Lite Converter](https://www.tensorflow.org/lite/models/convert/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiaoCj7GySsD"
      },
      "source": [
        "### Muat kumpulan data MNIST\n",
        "\n",
        "Kami memuat kumpulan data MNIST dari Keras dan mempersiapkannya untuk pelatihan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hMfSZQchySsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaed086-0058-41e1-ebea-233825305bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrNON1j5ySsD"
      },
      "source": [
        "### Latih Modelnya\n",
        "\n",
        "Selanjutnya, kita mendefinisikan model CNN dan melatihnya pada dataset MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QVQjEjU7ySsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205f4877-4dd6-42c4-e15e-9c9700af52dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 36s 18ms/step - loss: 0.2746 - accuracy: 0.9221 - val_loss: 0.1257 - val_accuracy: 0.9660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7f19297a00a0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1,\n",
        "  validation_data=(test_images, test_labels)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBi1S5ZDySsD"
      },
      "source": [
        "### Konversi Model ke TFLite\n",
        "\n",
        "Setelah melatih model, kami mengonversinya ke format [TFLite](https://www.tensorflow.org/lite/guide ) dan kemudian melakukan kuantisasi selama konversi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ULdc39PGySsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66eaf20-2034-4e31-95fa-f807094b34bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23968"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tflite_models_dir = pathlib.Path(\"notebooks/Unit 9 - Model Optimization/models\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# without quantization\n",
        "tflite_model = converter.convert()\n",
        "tflite_model_file = tflite_models_dir/\"original_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "\n",
        "# with quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"quantized_model.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXESDmt3ySsD"
      },
      "source": [
        "### Periksa Ukuran Model\n",
        "\n",
        "Ukuran model terkuantisasi jauh lebih kecil dibandingkan model aslinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vLu46cIuySsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3cf6a3b-4ae6-4b12-8ac7-21617602ce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'notebooks/Unit': No such file or directory\n",
            "ls: cannot access '9': No such file or directory\n",
            "ls: cannot access '-': No such file or directory\n",
            "ls: cannot access 'Model': No such file or directory\n",
            "ls: cannot access 'Optimization/models': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%ls -lh {tflite_models_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XbcnPsTySsE"
      },
      "source": [
        "### Periksa Akurasi Model\n",
        "\n",
        "Selanjutnya, kami mengevaluasi keakuratan model terkuantisasi pada kumpulan data pengujian dan membandingkannya dengan model aslinya.\n",
        "Berdasarkan hasil terlihat bahwa keakuratan model terkuantisasi sangat mendekati model aslinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YFotjxRrySsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5c8d29-1bf9-43b4-c98c-c17e025fdf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model accuracy =  0.966\n",
            "Quantized model accuracy =  0.9659\n"
          ]
        }
      ],
      "source": [
        "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for test_image in test_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == test_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()\n",
        "print(\"Original model accuracy = \", evaluate_model(interpreter))\n",
        "\n",
        "\n",
        "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
        "interpreter_quant.allocate_tensors()\n",
        "print(\"Quantized model accuracy = \", evaluate_model(interpreter_quant))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOvjDj4JySsE"
      },
      "source": [
        "## Pemangkasan\n",
        "\n",
        "Pemangkasan merupakan suatu teknik untuk memperkecil ukuran model dengan menghilangkan beban-beban yang tidak penting. Hal ini ditentukan oleh besarnya bobot. Kita dapat menggunakan pemangkasan saat melatih model untuk memperkecil ukuran model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "phci8zZsySsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad1ee44-4f99-441a-d2d5-4ce51f3943b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_reshap  (None, 28, 28, 1)         1         \n",
            " e (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 26, 26, 12)        230       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 13, 13, 12)        1         \n",
            " oling2d (PruneLowMagnitude                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 2028)              1         \n",
            " n (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dense   (None, 10)                40572     \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40805 (159.41 KB)\n",
            "Trainable params: 20410 (79.73 KB)\n",
            "Non-trainable params: 20395 (79.69 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "422/422 [==============================] - 18s 35ms/step - loss: 0.1570 - accuracy: 0.9599 - val_loss: 0.1520 - val_accuracy: 0.9693\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 14s 34ms/step - loss: 0.1528 - accuracy: 0.9616 - val_loss: 0.1095 - val_accuracy: 0.9732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7f1929e85930>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model_for_pruning.summary())\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_images, train_labels,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPjfOadiySsE"
      },
      "source": [
        "### Bandingkan Akurasi\n",
        "\n",
        "Terlihat bahwa keakuratan model yang dipangkas sangat mendekati model aslinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z98mp8TGySsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2cc94a-128e-41b0-a976-62cc2dcd3c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.965399980545044\n",
            "Pruned test accuracy: 0.965399980545044\n"
          ]
        }
      ],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Pruned test accuracy:', model_for_pruning_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVZJCS-pySsE"
      },
      "source": [
        "### Bandingkan Ukuran Model\n",
        "\n",
        "Terakhir, kami membandingkan ukuran model yang dipangkas dengan model aslinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ex3TgjuQySsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d9417a-9dba-4f10-f56e-ba4168f0a865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84616"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "pruning_converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = pruning_converter.convert()\n",
        "pruned_model_file = tflite_models_dir/\"pruned_model.tflite\"\n",
        "pruned_model_file.write_bytes(pruned_tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ikVxwCgVySsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6d5482-4919-4aa2-e12e-971aae8196ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'notebooks/Unit': No such file or directory\n",
            "ls: cannot access '9': No such file or directory\n",
            "ls: cannot access '-': No such file or directory\n",
            "ls: cannot access 'Model': No such file or directory\n",
            "ls: cannot access 'Optimization/models': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%ls -lh {tflite_models_dir}"
      ]
    }
  ]
}